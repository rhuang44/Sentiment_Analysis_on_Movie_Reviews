{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background information:\n",
    "The dataset is from Rotten Tomatoes dataset consist of audience reviews and sentiments. \n",
    "\n",
    "The sentiment labels are: \\\n",
    "0 - negative \\\n",
    "1 - somewhat negative \\\n",
    "2 - neutral \\\n",
    "3 - somewhat positive \\\n",
    "4 - positive \n",
    "\n",
    "If the sentiment score is larger or equal than 3, then the moive is treated as 'good' moive, or it is a 'bad' one. The objective of the tutorial is to predict the quality of moive (good/bad) based on audience's review. \n",
    "\n",
    "\n",
    "data source: https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/overview  \n",
    "code reference: https://www.linkedin.com/learning/nlp-with-python-for-machine-learning-essential-training/welcome?u=53565897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             Phrase\n",
       "0   bad  A series of escapades demonstrating the adage ...\n",
       "1   bad  A series of escapades demonstrating the adage ...\n",
       "2   bad                                           A series\n",
       "3   bad                                                  A\n",
       "4   bad                                             series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the raw text\n",
    "raw_data = pd.read_csv('Sentiment_Analysis_on_Movie_Reviews.tsv',sep='\\t')\n",
    "\n",
    "# filter\n",
    "raw_data['label'] = raw_data['Sentiment'].apply(lambda x: 'good' if x >= 3 else 'bad') \n",
    "raw_data.head()\n",
    "data = raw_data[['label','Phrase']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21a000872c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"label\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data has 156060 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "## shape of the dataset\n",
    "print(\"Input data has {} rows and {} columns\".format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "#### Pre-processing text data\n",
    "\n",
    "1. Remove punctuation\n",
    "2. Tokenization\n",
    "3. Remove stopwords\n",
    "4. Lemmatize/Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation]) # Remove punctuation\n",
    "    tokens = re.split('\\W+', text) # Tokenization\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords] # Remove stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>A series</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad</td>\n",
       "      <td>series</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             Phrase Phrase_clean\n",
       "0   bad  A series of escapades demonstrating the adage ...          NaN\n",
       "1   bad  A series of escapades demonstrating the adage ...          NaN\n",
       "2   bad                                           A series          NaN\n",
       "3   bad                                                  A          NaN\n",
       "4   bad                                             series          NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data.iloc[:5]\n",
    "sample.loc[:, 'Phrase_clean'] = sample[['Phrase']].apply(lambda x: clean_text(x))\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['Phrase']], data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1490</th>\n",
       "      <th>1491</th>\n",
       "      <th>1492</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "      <th>1498</th>\n",
       "      <th>1499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  1490  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   1491  1492  1493  1494  1495  1496  1497  1498  1499  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text, max_features=1500)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['Phrase'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['Phrase'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['Phrase'])\n",
    "\n",
    "X_train_vect = pd.DataFrame(tfidf_train.toarray())\n",
    "X_test_vect = pd.DataFrame(tfidf_test.toarray())\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building classifers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='good', average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature importance\n",
    "# reference: https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Bossting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "start = time.time()\n",
    "gb_model = gb.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gb_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further work:\n",
    "\n",
    "1. PCA visulization\n",
    "2. TF-IDF/bag of words/BERT\n",
    "3. NN classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
